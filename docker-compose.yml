
# docker-compose.yml

networks:
  kafka-net:
    driver: bridge

services:

  # 1. Zookeeper 서비스
  zookeeper:
    image: confluentinc/cp-zookeeper:latest # 가지고 계신 주키퍼 이미지 이름으로 변경 가능
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - kafka-net
    ports:
      - "2181:2181" # 주키퍼 기본 포트
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # 2. Kafka 서비스
  kafka:
    image: confluentinc/cp-kafka:latest # 가지고 계신 카프카 이미지 이름으로 변경 가능
    container_name: kafka
    hostname: kafka
    networks:
      - kafka-net
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper # Zookeeper가 실행된 후에 Kafka가 시작되도록 의존성 설정
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181' # docker-compose 네트워크 내에서 zookeeper 서비스 이름으로 접근
      # 내부 리스너 설정 (컨테이너 간 통신)
      # 외부 리스너 설정 (호스트 머신에서 접근)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://172.30.1.1:29092 # kafka:9092(내부용) , localhost:29092(외부용)
      # 단일 노드 클러스터 설정 (운영 환경에서는 Replication Factor를 1보다 크게 설정해야 함)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # (선택) JMX 포트 (모니터링 등에 사용)
      # KAFKA_JMX_PORT: 9999
      # KAFKA_JMX_HOSTNAME: localhost
      # --- 최대 메시지 크기 설정 ---
      KAFKA_MESSAGE_MAX_BYTES: '10485760' # 10MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: '10485760' # 10MB (message.max.bytes 이상이어야 함)
      KAFKA_FETCH_MESSAGE_MAX_BYTES: '10485760' # 10MB (컨슈머 측 제한도 함께 조정)
      # ---------------------------

  # 3. Kafka UI 서비스 (Provectus Kafka UI 기준)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest # 가지고 계신 UI 이미지 이름으로 변경 가능
    container_name: kafka-ui
    networks:
      - kafka-net
    ports:
      - "8080:8080" # Kafka UI 웹 인터페이스 포트
    depends_on:
      - kafka # Kafka가 실행된 후에 UI가 시작되도록 의존성 설정
      - zookeeper
    environment:
      # Kafka 클러스터 설정 (UI 내에서 식별할 이름 및 접속 정보)
      KAFKA_CLUSTERS_0_NAME: local-kafka-cluster # UI에 표시될 클러스터 이름
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092 # UI 컨테이너가 Kafka 컨테이너에 접속할 주소 (내부 리스너 사용)
      # (선택) 주키퍼 연결 정보 (일부 기능에 필요할 수 있음)
      # KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      # (선택) 동적 설정을 UI에서 가능하게 할지 여부
      # DYNAMIC_CONFIG_ENABLED: "true"



  database:
    image: mariadb:10.7
    
    networks:
      - kafka-net

    hostname: Database
    container_name: Database
    ports:
        - "3306:3306" # 테스트 시 충돌 문제로 3307 remote
    environment:
      MARIADB_ROOT_PASSWORD: 1234 # MariaDB root 비밀번호
      #MARIADB_DATABASE: EDR # 생성할 데이터베이스 이름
      #MARIADB_USER: root # 생성할 사용자 이름
      #MARIADB_PASSWORD: 1234 # 생성할 사용자 비밀번호

    healthcheck:
       test: ["CMD-SHELL", "mysqladmin ping -hlocalhost -uroot -p$$MARIADB_ROOT_PASSWORD --silent"]
       interval: 10s
       timeout: 5s
       retries: 5
       start_period: 30s # 초기화 시간을 고려하여 첫 healthcheck까지 대기 (MariaDB는 초기화에 시간이 걸릴 수 있음)
    volumes:
      - db_data:/var/lib/mysql # 데이터 지속성을 위한 볼륨 마운트

  analysis_server:
      build:
        context: .
        dockerfile: ./AnalysisServer_Dockerfile
      hostname: analysis_server
      container_name: analysis_server
      
      networks:
      - kafka-net

      environment:
      # DB
        DB_HOST: "Database" # DB 서버 IP
        # DB_PORT: "3306" # 예시 포트 번호
      # Elasticsearch
        ELASTICSEARCH_HOST: "172.30.1.254" # Elasticsearch 서버 IP --> 기본값 
        # ELASTICSEARCH_PORT: "9200" # 예시 엘라스틱서치 포트 번호 --> 기본값 
      # Kafka
        # KAFKA_HOST: "172.30.1.254" # Kafka 서버 IP --> 기본값 
        # KAFKA_PORT: "9092" # 예시 카프카 포트 --> 기본값 
      # Analysis Server
        # ANALYSIS_SERVER_HOST: "0.0.0.0" # 분석 서버 IP - 같은 호스트 --> 기본값 
        # ANALYSIS_SERVER_PORT: "6060" # 예시 포트 번호 6060 --> 기본값
      ports:
        - "6060:6060" # 분석 서버 포트
      depends_on:
        - database


  core_server:
      build:
        context: .
        dockerfile: ./CoreServer_Dockerfile
      hostname: core_server
      container_name: core_server
      
      networks:
      - kafka-net

      environment:
      # DB
        TZ: "Asia/Seoul" # 타임존 설정
        DB_HOST: "Database" # DB 서버 IP
        # DB_PORT: "3306" # 예시 포트 번호
      # Elasticsearch
        ELASTICSEARCH_HOST: "172.30.1.254" # Elasticsearch 서버 IP --> 기본값 
        # ELASTICSEARCH_PORT: "9200" # 예시 엘라스틱서치 포트 번호 --> 기본값 
      # Kafka
        KAFKA_HOST: "kafka" # Kafka 서버 IP --> 기본값 
        KAFKA_PORT: "9092" # 예시 카프카 포트 --> 기본값 
      # Analysis Server
        ANALYSIS_SERVER_HOST: "analysis_server" # 분석 서버 hostname
        # ANALYSIS_SERVER_PORT: "6060" # 예시 포트 번호 6060 --> 기본값
      # Local Storage
        #LOCAL_STORAGE_DIR: "./save_file" # 예시 (수동 지정 안함 추천..  EXE바이너리 저장소 ) --> 기본값 
      ports:
        - "10000:10000" # 코어서버의 RestAPI 서버 포트
        - "10299:10299" # 코어서버의 에이전트 수신 포트
      depends_on:
        database:
          condition: service_healthy 
      volumes:
        - save_file:/CoreServer/save_file # 내부 /CoreServer/save_file - EXE바이너리 절대 저장소 경로
  suricata:
    build:
        context: .
        dockerfile: ./NDR_Dockerfile
    hostname: suricata
    container_name: suricata
    
    privileged: true

    network_mode: "host"
    environment:
      # DB
        DB_HOST: "Database" # DB 서버 IP
        # DB_PORT: "3306" # 예시 포트 번호
      # Elasticsearch
        ELASTICSEARCH_HOST: "172.30.1.254" # Elasticsearch 서버 IP --> 기본값 
        # ELASTICSEARCH_PORT: "9200" # 예시 엘라스틱서치 포트 번호 --> 기본값 
      # Kafka
        KAFKA_HOST: "kafka" # Kafka 서버 IP --> 기본값 
        # KAFKA_PORT: "9092" # 예시 카프카 포트 --> 기본값 

    depends_on:
      - database
      - kafka

# Docker Named Volumes 정의
volumes:
    
  db_data: # 마리아 DB 
    driver: local

  save_file: # EXE바이너리 저장소
    driver: local